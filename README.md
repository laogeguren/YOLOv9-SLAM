# YOLOv9-SLAM
A SLAM localization and mapping system for dynamic environments with YOLOv9 as the front-end object detection


Use YOLOv9 to detect the image, and transfer the detected box data file to SLAM for use；
Use orbslam2 to read the detection box in the folder and remove the dynamic feature points according to the box。
Dataset download link
https://vision.in.tum.de/data/datasets/rgbd-dataset/download#freiburg3_walking_xyz

Compilation method
Reference ORBSLAM2 Reference YOLOV9

Run YOLOv9
Run the main.py file in yolov9-main. Perform YOLO detection on the original images of the dataset. This will generate data files that can be used by SLAM after object detection.

SLAM run command with yolo detection results
run the dataset in yolo-main for box extraction
./Examples/RGB-D/rgbd_tum Vocabulary/ORBvoc.txt Examples/RGB-D/TUM3.yaml /home/zs/YOLOV9_ORB_SLAM/tum/rgbd_dataset_freiburg3_walking_xyz_validation /home/zs/YOLOV9_ORB_SLAM/tum/rgbd_dataset_freiburg3_walking_xyz_validation/zs1.txt /home/zs/YOLOV9_ORB_SLAM/tum/rgbd_dataset_freiburg3_walking_xyz_validation/result01/

Files required to execute the command
ORBvoc.txt Pre-trained bag-of-words model file TUM.yaml Weight file rgbd_dataset_freiburg3_walking_xyz_validation Dataset file zs1.txt File generated by aligning RGB and depth images using timestamps result01 Data file generated by YOLO detection
